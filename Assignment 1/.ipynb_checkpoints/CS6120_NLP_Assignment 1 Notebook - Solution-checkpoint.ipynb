{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc97d6da",
   "metadata": {},
   "source": [
    "## CS 6120: Natural Language Processing - Prof. Ahmad Uzair\n",
    "\n",
    "### Assignment 1: Naive Bayes\n",
    "### Total Points: 100 points\n",
    "\n",
    "In this assignment, you would be working with SMS data that contains SPAM or HAM messages. When you take a look at your gmail account, you find that a few emails are classified as spam. Similarly, some text messages that are received on the phone are also classified as spam based on a set of characteristics such as wording and so on. \n",
    "\n",
    "Therefore, we are going to address this problem of detecting SPAM or HAM messages with the help of Naive Bayes algorithm.\n",
    "\n",
    "## Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a03450ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc584cc2",
   "metadata": {},
   "source": [
    "## Reading the data\n",
    "\n",
    "When reading the data, ensure that the '.csv' file is in the same location where your jupyter notebook is used. This way the files are organized and easy to read using the pandas library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c9ffbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading the data and removing columns that are not important. \n",
    "df = pd.read_csv('spam.csv', sep = ',', encoding = 'latin-1', usecols = lambda col: col not in [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7fa8ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)  # print head of data frame with help of head function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aecf75db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Renaming the columns so that we understand the columns easily.\n",
    "\n",
    "## Rename v1 as \"spam_or_ham\" and v2 as \"message\"\n",
    "\n",
    "df = df.rename(columns = {\"v1\":\"spam_or_ham\", \"v2\":\"message\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6fc153c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam_or_ham</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  spam_or_ham                                            message\n",
       "0         ham  Go until jurong point, crazy.. Available only ...\n",
       "1         ham                      Ok lar... Joking wif u oni...\n",
       "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         ham  U dun say so early hor... U c already then say...\n",
       "4         ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)  # print head of data frame with help of head function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1749da04",
   "metadata": {},
   "source": [
    "## Count plot of the output categories: spam or ham\n",
    "\n",
    "Feel free to take a look at the output and whether the classes are balanced or imbalanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c152e8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "sns.countplot(x=\"spam_or_ham\",data=df)\n",
    "plt.title(\"Spam Vs. Ham Messages count\", fontsize = 15)\n",
    "plt.show()\n",
    "\n",
    "#Class is imbalanced as there way more Ham messages than Span messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8549f2",
   "metadata": {},
   "source": [
    "## Upsampling the minority class: (5 points)\n",
    "\n",
    "It is known that Naive bayes is not robust to class imbalance. It could be seen above that the data is quite imbalanced. Therefore, class balancing must be done before giving it to the Naive Bayes model for prediction. \n",
    "\n",
    "Feel free to use 'resample' library from sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80f27192",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hint: use resample from sklearn.utils\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = df[df.spam_or_ham=='ham']\n",
    "df_minority = df[df.spam_or_ham=='spam']\n",
    "\n",
    "spam_upsample = resample(df_minority, replace = True, \n",
    "                        n_samples = df_majority.shape[0],\n",
    "                        random_state = 101)\n",
    "\n",
    "df_upsampled = pd.concat([df_majority, spam_upsample])  # concat two data frames i,e majority class data set and upsampled minority class data set\n",
    "df_upsampled = df_upsampled.sample(frac = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a9329bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4825, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Just to ensure that upsampling was done successfully, take a look at the shape of the data in \n",
    "## this cell. \n",
    "\n",
    "# print the shape of data set with the help of shape function having \"spam\" as class label\n",
    "df_upsampled[df_upsampled['spam_or_ham']==\"spam\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8bf6e7",
   "metadata": {},
   "source": [
    "### Expected Output : \n",
    "(4825, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdea8155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4825, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Ensure that the same number of data points are present for both 'spam' and 'ham' data\n",
    "\n",
    "# print the shape of data set with the help of shape function having \"ham\" as class label\n",
    "df_upsampled[df_upsampled['spam_or_ham']==\"ham\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626f01d5",
   "metadata": {},
   "source": [
    "### Expected Output : \n",
    "(4825, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61eb9d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "## In this cell, we are going to be dividing the data into train and test points\n",
    "## Ensure that you store the upsampled data in a variable called 'df_upsampled' \n",
    "## so that the below operations are performed successfully\n",
    "\n",
    "\n",
    "## Considering 3000 spam and 3000 ham data points\n",
    "spam_data_points_train = df_upsampled[df_upsampled['spam_or_ham']==\"spam\"].iloc[:3000]\n",
    "ham_data_points_train = df_upsampled[df_upsampled['spam_or_ham']==\"ham\"].iloc[:3000]\n",
    "\n",
    "## Considering the remaining data points for test\n",
    "spam_data_points_test = df_upsampled[df_upsampled['spam_or_ham']==\"spam\"].iloc[3000:]\n",
    "ham_data_points_test = df_upsampled[df_upsampled['spam_or_ham']==\"ham\"].iloc[3000:]\n",
    "\n",
    "\n",
    "## Concatenate the training ham and spam messages\n",
    "X_train = pd.concat([spam_data_points_train['message'], ham_data_points_train['message']])\n",
    "\n",
    "## Concatenating the training ham and spam outputs\n",
    "y_train = pd.concat([spam_data_points_train['spam_or_ham'], ham_data_points_train['spam_or_ham']])\n",
    "\n",
    "## Concatenating the test ham and spam messages\n",
    "X_test = pd.concat([spam_data_points_test['message'], ham_data_points_test['message']])\n",
    "## Concatenating the test ham and spam outputs\n",
    "y_test = pd.concat([spam_data_points_test['spam_or_ham'], ham_data_points_test['spam_or_ham']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec7832b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam    3000\n",
       "ham     3000\n",
       "Name: spam_or_ham, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Take a look at the total number of classes and their count using '.value_counts()' for y_train and y_test.\n",
    "## Ensure that there are equal number of spam and ham messages. \n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfe6517",
   "metadata": {},
   "source": [
    "### Expected Output:\n",
    "spam    3000<br>\n",
    "ham     3000<br>\n",
    "Name: spam_or_ham, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2beae1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam    1825\n",
       "ham     1825\n",
       "Name: spam_or_ham, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9163f897",
   "metadata": {},
   "source": [
    "### Expected Output : \n",
    "spam    1825<br>\n",
    "ham     1825<br>\n",
    "Name: spam_or_ham, dtype: int64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6501699b",
   "metadata": {},
   "source": [
    "## Pre-process the messages: (15 points)\n",
    "\n",
    "We know that a message contains links, punctuation, stopwords and many other words that don't give a lot of meaning for the Naive Bayes model for prediction. \n",
    "\n",
    "In the cell below, one must implement text-preprocessing and remove links, punctuations and stopwords. It is also important to lowercase the letters so that 'Admire' and 'admire' are not treated as different words. \n",
    "\n",
    "In addition to this, perform stemming operation so that similar words are reduced. To know more about stemming, feel free to take a look at this link.\n",
    "\n",
    "https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd4ce1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK CELL\n",
    "#Stopword Removal \n",
    "#import stopwords from nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "porter_stemmer = PorterStemmer()\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#Support functions\n",
    "#Stopwords\n",
    "def remove_stopwords(message):\n",
    "    output= [i for i in message if i not in stopwords]\n",
    "    return output\n",
    "\n",
    "#Stemming\n",
    "def stemming(message):\n",
    "    stem_text = [porter_stemmer.stem(word) for word in message]\n",
    "    return stem_text\n",
    "\n",
    "#Lemmatization\n",
    "def lemmatizer(message):\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in message]\n",
    "    return lemm_text\n",
    "\n",
    "def clean_message(message):\n",
    "    '''\n",
    "    Input:\n",
    "        message: a string containing a message.\n",
    "    Output:\n",
    "        messages_cleaned: a list of words containing the processed message. \n",
    "\n",
    "    '''\n",
    "    #Remove Punctuations\n",
    "    messages_cleaned=\"\".join([i for i in message if i not in string.punctuation])\n",
    "    #Convert to lowercase\n",
    "    messages_cleaned= messages_cleaned.lower()\n",
    "    #Tokenize words\n",
    "    messages_cleaned= nltk.word_tokenize(messages_cleaned)\n",
    "    #Remove stopwords\n",
    "    messages_cleaned=remove_stopwords(messages_cleaned)\n",
    "    #Stemming\n",
    "    messages_cleaned=stemming(messages_cleaned)\n",
    "    #Lemmatization\n",
    "    messages_cleaned=lemmatizer(messages_cleaned)\n",
    "    \n",
    "    return messages_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7632fe5",
   "metadata": {},
   "source": [
    "## Implement a find_occurrence function (5 points):\n",
    "\n",
    "In this function, we find the total occurrence of a word giving information such as label, word and frequency dictionary.\n",
    "\n",
    "Note that this function is used later in the code when we are going to be predicting the output using Naive Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb282b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK CELL\n",
    "def find_occurrence(frequency, word, label):\n",
    "    '''\n",
    "    Params:\n",
    "        frequency: a dictionary with the frequency of each pair (or tuple)\n",
    "        word: the word to look up\n",
    "        label: the label corresponding to the word\n",
    "    Return:\n",
    "        n: the number of times the word with its corresponding label appears.\n",
    "    '''\n",
    "    n = frequency[(word,label)]\n",
    "\n",
    "    return n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a2249d",
   "metadata": {},
   "source": [
    "## Converting output to numerical format:\n",
    "\n",
    "We have outputs as 'ham' or 'spam'. In the cell below, we convert it to a numerical format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcdc2b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## With the use of mapping function, we replace\n",
    "## the label in the form of string to an integer. \n",
    "\n",
    "output_map = {'ham': 0, 'spam': 1}\n",
    "y_train = y_train.map(output_map)\n",
    "y_test = y_test.map(output_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dde0bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3000\n",
       "0    3000\n",
       "Name: spam_or_ham, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Ensuring that there are equal number of classes on the training data. \n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2959b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You have won a Nokia 7250i. This is what you get when you win our FREE auction. To take part send Nokia to 86021 now. HG/Suite342/2Lands Row/W1JHL 16+ '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Choosing a random message and taking a look at it.\n",
    "X_train.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5e43c9",
   "metadata": {},
   "source": [
    "From the above cell output, it could be seen that there are a lot of words that don't add a lot of meaning to the text. \n",
    "\n",
    "Therefore, those words would be removed. It also reduces the computation time. \n",
    "\n",
    "Therefore, it is a good practice we are following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad3937ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nokia', '7250i', 'get', 'win', 'free', 'auction', 'take', 'part', 'send', 'nokia', '86021', 'hgsuite3422land', 'roww1jhl', '16']\n"
     ]
    }
   ],
   "source": [
    "custom_message = X_train.iloc[0]\n",
    "\n",
    "# print cleaned message\n",
    "                         \n",
    "print(clean_message(custom_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6cc440",
   "metadata": {},
   "source": [
    "We now use this function to pre-process the message and remove words that don't add a lot of meaning in our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a762960",
   "metadata": {},
   "source": [
    "## Implementing message counter function: (10 points)\n",
    "\n",
    "It is now time to implement the count function for the messages. \n",
    "\n",
    "In this function, we count the occurrence of words and get the probabilities \n",
    "for the words based on the training data. \n",
    "\n",
    "In other words, we get the probability of occurrence of a word, given that the output is 'spam'.\n",
    "\n",
    "Similarly, we also compute the probability of occurence of a word, given that the output is 'ham'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5de61f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK CELL\n",
    "def message_counter(output_occurrence, messages, spam_or_ham):\n",
    "    '''\n",
    "    Params:\n",
    "        output_occurrence: a dictionary that will be used to map each pair to its frequency\n",
    "        messages: a list of messages\n",
    "        spam_or_ham: a list corresponding to the sentiment of each message (either 0 or 1)\n",
    "    Return:\n",
    "        output: a dictionary mapping each pair to its frequency\n",
    "    '''\n",
    "    ## Steps :\n",
    "    # define the key, which is the word and label tuple\n",
    "    # if the key exists in the dictionary, increment the count\n",
    "    # else, if the key is new, add it to the dictionary and set the count to 1\n",
    "    for label, message in zip(spam_or_ham, messages):\n",
    "        for word in clean_message(message):\n",
    "            if (word,label) in output_occurrence:\n",
    "                output_occurrence[(word,label)] += 1\n",
    "            else:\n",
    "                output_occurrence[(word,label)] =1\n",
    "                \n",
    "   \n",
    "    \n",
    "    return output_occurrence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18238223",
   "metadata": {},
   "source": [
    "## Test your function with example messages:\n",
    "\n",
    "Feel free to run the cell below and understand whether the above function that you have defined is producing the optimum results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07a4c58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('get', 1): 2,\n",
       " ('offer', 1): 1,\n",
       " ('upto', 1): 1,\n",
       " ('20', 1): 1,\n",
       " ('come', 0): 1,\n",
       " ('click', 1): 1,\n",
       " ('link', 1): 1,\n",
       " ('latest', 1): 1,\n",
       " ('car', 1): 1,\n",
       " ('canva', 0): 1,\n",
       " ('class', 0): 1,\n",
       " ('schedul', 0): 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing your function\n",
    "\n",
    "result = {}\n",
    "messages = ['get offer upto 20%', 'I am coming now', 'Click on the link', 'get a latest car', 'canvas class scheduled']\n",
    "ys = [1, 0, 1, 1, 0]\n",
    "message_counter(result,messages, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927f89bb",
   "metadata": {},
   "source": [
    "### Expected Output:\n",
    "{('get', 1): 2, <br>\n",
    " ('offer', 1): 1, <br>\n",
    " ('upto', 1): 1, <br>\n",
    " ('20', 1): 1, <br>\n",
    " ('i', 0): 1, <br>\n",
    " ('come', 0): 1, <br>\n",
    " ('click', 1): 1, <br>\n",
    " ('link', 1): 1, <br>\n",
    " ('latest', 1): 1, <br>\n",
    " ('car', 1): 1, <br>\n",
    " ('canva', 0): 1, <br>\n",
    " ('class', 0): 1, <br>\n",
    " ('schedul', 0): 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bc62e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the freqs dictionary for later uses\n",
    "\n",
    "freqs = message_counter({}, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0eddf420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('nokia', 1): 312,\n",
       " ('7250i', 1): 15,\n",
       " ('get', 1): 379,\n",
       " ('win', 1): 239,\n",
       " ('free', 1): 949,\n",
       " ('auction', 1): 81,\n",
       " ('take', 1): 96,\n",
       " ('part', 1): 55,\n",
       " ('send', 1): 264,\n",
       " ('86021', 1): 28,\n",
       " ('hgsuite3422land', 1): 38,\n",
       " ('roww1jhl', 1): 15,\n",
       " ('16', 1): 219,\n",
       " ('u', 1): 623,\n",
       " ('r', 1): 85,\n",
       " ('winner', 1): 76,\n",
       " ('ave', 1): 12,\n",
       " ('special', 1): 84,\n",
       " ('select', 1): 128,\n",
       " ('2', 1): 729,\n",
       " ('receiv', 1): 168,\n",
       " ('å£1000', 1): 160,\n",
       " ('cash', 1): 258,\n",
       " ('4', 1): 508,\n",
       " ('holiday', 1): 128,\n",
       " ('flight', 1): 32,\n",
       " ('inc', 1): 35,\n",
       " ('speak', 1): 39,\n",
       " ('live', 1): 103,\n",
       " ('oper', 1): 55,\n",
       " ('claim', 1): 457,\n",
       " ('0871277810710pmin', 1): 4,\n",
       " ('18', 1): 164,\n",
       " ('chanc', 1): 113,\n",
       " ('realiti', 1): 4,\n",
       " ('fantasi', 1): 30,\n",
       " ('show', 1): 130,\n",
       " ('call', 1): 1455,\n",
       " ('08707509020', 1): 19,\n",
       " ('20p', 1): 20,\n",
       " ('per', 1): 182,\n",
       " ('min', 1): 194,\n",
       " ('ntt', 1): 29,\n",
       " ('ltd', 1): 48,\n",
       " ('po', 1): 106,\n",
       " ('box', 1): 111,\n",
       " ('1327', 1): 20,\n",
       " ('croydon', 1): 20,\n",
       " ('cr9', 1): 20,\n",
       " ('5wb', 1): 20,\n",
       " ('0870', 1): 12,\n",
       " ('nation', 1): 39,\n",
       " ('rate', 1): 103,\n",
       " ('urgent', 1): 262,\n",
       " ('mobil', 1): 561,\n",
       " ('077xxx', 1): 8,\n",
       " ('å£2000', 1): 141,\n",
       " ('bonu', 1): 92,\n",
       " ('caller', 1): 61,\n",
       " ('prize', 1): 438,\n",
       " ('020603', 1): 23,\n",
       " ('2nd', 1): 95,\n",
       " ('attempt', 1): 101,\n",
       " ('reach', 1): 26,\n",
       " ('09066362206', 1): 8,\n",
       " ('asap', 1): 27,\n",
       " ('box97n7qp', 1): 16,\n",
       " ('150ppm', 1): 142,\n",
       " ('500', 1): 115,\n",
       " ('new', 1): 294,\n",
       " ('2004', 1): 35,\n",
       " ('must', 1): 20,\n",
       " ('go', 1): 139,\n",
       " ('txt', 1): 647,\n",
       " ('89545', 1): 15,\n",
       " ('collect', 1): 231,\n",
       " ('todayfrom', 1): 10,\n",
       " ('å£1', 1): 15,\n",
       " ('www4tcbiz', 1): 15,\n",
       " ('2optout', 1): 20,\n",
       " ('08718726270150gbpmtmsg18', 1): 15,\n",
       " ('hi', 1): 57,\n",
       " ('2night', 1): 3,\n",
       " ('ur', 1): 620,\n",
       " ('lucki', 1): 37,\n",
       " ('night', 1): 25,\n",
       " ('uve', 1): 23,\n",
       " ('invit', 1): 47,\n",
       " ('xchat', 1): 19,\n",
       " ('uk', 1): 94,\n",
       " ('wildest', 1): 3,\n",
       " ('chat', 1): 153,\n",
       " ('86688', 1): 77,\n",
       " ('150pmsgrcvdhgsuite3422landsroww1j6hl', 1): 17,\n",
       " ('ldn', 1): 39,\n",
       " ('18yr', 1): 14,\n",
       " ('secret', 1): 40,\n",
       " ('admir', 1): 40,\n",
       " ('reveal', 1): 32,\n",
       " ('think', 1): 57,\n",
       " ('09065174042', 1): 9,\n",
       " ('opt', 1): 47,\n",
       " ('repli', 1): 476,\n",
       " ('stop', 1): 441,\n",
       " ('150', 1): 44,\n",
       " ('msg', 1): 111,\n",
       " ('recd', 1): 14,\n",
       " ('cust', 1): 17,\n",
       " ('care', 1): 36,\n",
       " ('07821230901', 1): 9,\n",
       " ('credit', 1): 71,\n",
       " ('top', 1): 61,\n",
       " ('httpwwwbubbletextcom', 1): 1,\n",
       " ('renew', 1): 8,\n",
       " ('pin', 1): 1,\n",
       " ('tgxxrz', 1): 1,\n",
       " ('guarante', 1): 224,\n",
       " ('latest', 1): 158,\n",
       " ('phone', 1): 228,\n",
       " ('40gb', 1): 20,\n",
       " ('ipod', 1): 45,\n",
       " ('mp3', 1): 19,\n",
       " ('player', 1): 43,\n",
       " ('å£500', 1): 67,\n",
       " ('word', 1): 74,\n",
       " ('83355', 1): 19,\n",
       " ('ibhltd', 1): 13,\n",
       " ('ldnw15h', 1): 13,\n",
       " ('150pmtmsgrcvd18', 1): 13,\n",
       " ('thank', 1): 78,\n",
       " ('rington', 1): 134,\n",
       " ('order', 1): 70,\n",
       " ('ref', 1): 14,\n",
       " ('number', 1): 148,\n",
       " ('r836', 1): 10,\n",
       " ('charg', 1): 111,\n",
       " ('å£450', 1): 23,\n",
       " ('tone', 1): 333,\n",
       " ('arriv', 1): 31,\n",
       " ('plea', 1): 216,\n",
       " ('custom', 1): 221,\n",
       " ('servic', 1): 263,\n",
       " ('09065069154', 1): 10,\n",
       " ('want', 1): 119,\n",
       " ('xma', 1): 83,\n",
       " ('100', 1): 73,\n",
       " ('text', 1): 531,\n",
       " ('messag', 1): 156,\n",
       " ('video', 1): 115,\n",
       " ('half', 1): 60,\n",
       " ('price', 1): 65,\n",
       " ('line', 1): 163,\n",
       " ('rental', 1): 54,\n",
       " ('0800', 1): 44,\n",
       " ('0721072', 1): 3,\n",
       " ('find', 1): 72,\n",
       " ('camera', 1): 139,\n",
       " ('12', 1): 41,\n",
       " ('mth', 1): 17,\n",
       " ('cross', 1): 11,\n",
       " ('ntwk', 1): 16,\n",
       " ('mobileupd8', 1): 72,\n",
       " ('08001950382', 1): 17,\n",
       " ('call2optout674', 1): 10,\n",
       " ('natalja', 1): 6,\n",
       " ('25f', 1): 6,\n",
       " ('friend', 1): 80,\n",
       " ('yes440', 1): 6,\n",
       " ('no440', 1): 6,\n",
       " ('see', 1): 76,\n",
       " ('wwwsmsacunat27081980', 1): 6,\n",
       " ('frnd', 1): 28,\n",
       " ('62468', 1): 28,\n",
       " ('look', 1): 44,\n",
       " ('make', 1): 46,\n",
       " ('contact', 1): 242,\n",
       " ('ufind', 1): 31,\n",
       " ('rreveal', 1): 31,\n",
       " ('specialcal', 1): 31,\n",
       " ('09058094594', 1): 7,\n",
       " ('b4u', 1): 8,\n",
       " ('voucher', 1): 146,\n",
       " ('wc', 1): 8,\n",
       " ('2703', 1): 8,\n",
       " ('marsm', 1): 8,\n",
       " ('log', 1): 37,\n",
       " ('onto', 1): 37,\n",
       " ('wwwb4utelecom', 1): 8,\n",
       " ('discount', 1): 42,\n",
       " ('08717168528', 1): 8,\n",
       " ('4mth', 1): 14,\n",
       " ('orang', 1): 111,\n",
       " ('11mth', 1): 39,\n",
       " ('mobilesdirect', 1): 14,\n",
       " ('08000938767', 1): 14,\n",
       " ('updat', 1): 92,\n",
       " ('or2stoptxt', 1): 14,\n",
       " ('tc', 1): 197,\n",
       " ('hot', 1): 54,\n",
       " ('email', 1): 2,\n",
       " ('alertfrom', 1): 1,\n",
       " ('jeri', 1): 1,\n",
       " ('stewart', 1): 1,\n",
       " ('2kbsubject', 1): 1,\n",
       " ('lowcost', 1): 1,\n",
       " ('prescripiton', 1): 1,\n",
       " ('drvgsto', 1): 1,\n",
       " ('listen', 1): 13,\n",
       " ('123', 1): 13,\n",
       " ('laid', 1): 15,\n",
       " ('tonight', 1): 17,\n",
       " ('real', 1): 47,\n",
       " ('dog', 1): 56,\n",
       " ('locat', 1): 24,\n",
       " ('sent', 1): 53,\n",
       " ('direct', 1): 43,\n",
       " ('mob', 1): 116,\n",
       " ('join', 1): 84,\n",
       " ('largest', 1): 20,\n",
       " ('network', 1): 117,\n",
       " ('bt', 1): 25,\n",
       " ('txting', 1): 49,\n",
       " ('gravel', 1): 7,\n",
       " ('69888', 1): 10,\n",
       " ('nt', 1): 7,\n",
       " ('ec2a', 1): 20,\n",
       " ('31pmsg150p', 1): 11,\n",
       " ('hey', 1): 24,\n",
       " ('boy', 1): 11,\n",
       " ('xxx', 1): 47,\n",
       " ('pic', 1): 94,\n",
       " ('porn', 1): 20,\n",
       " ('69855', 1): 9,\n",
       " ('24hr', 1): 10,\n",
       " ('50p', 1): 18,\n",
       " ('day', 1): 102,\n",
       " ('stopbcm', 1): 9,\n",
       " ('sf', 1): 9,\n",
       " ('wc1n3xx', 1): 18,\n",
       " ('09061213237', 1): 9,\n",
       " ('landlin', 1): 129,\n",
       " ('å£5000', 1): 85,\n",
       " ('luxuri', 1): 4,\n",
       " ('canari', 1): 4,\n",
       " ('island', 1): 4,\n",
       " ('await', 1): 127,\n",
       " ('sae', 1): 92,\n",
       " ('177', 1): 9,\n",
       " ('m227xi', 1): 9,\n",
       " ('motorola', 1): 44,\n",
       " ('upto', 1): 13,\n",
       " ('12mth', 1): 10,\n",
       " ('12price', 1): 6,\n",
       " ('linerent', 1): 15,\n",
       " ('xnet', 1): 6,\n",
       " ('mins100txtmth', 1): 6,\n",
       " ('btooth', 1): 7,\n",
       " ('2optoutd3wv', 1): 6,\n",
       " ('11', 1): 21,\n",
       " ('month', 1): 36,\n",
       " ('entitl', 1): 36,\n",
       " ('colour', 1): 75,\n",
       " ('co', 1): 26,\n",
       " ('08002986030', 1): 13,\n",
       " ('bring', 1): 13,\n",
       " ('time', 1): 77,\n",
       " ('chart', 1): 16,\n",
       " ('hero', 1): 6,\n",
       " ('hit', 1): 13,\n",
       " ('week', 1): 279,\n",
       " ('wap', 1): 46,\n",
       " ('tip', 1): 6,\n",
       " ('romant', 1): 6,\n",
       " ('pari', 1): 18,\n",
       " ('å£79', 1): 6,\n",
       " ('book', 1): 27,\n",
       " ('next', 1): 59,\n",
       " ('year', 1): 57,\n",
       " ('08704439680tsc', 1): 6,\n",
       " ('appli', 1): 112,\n",
       " ('tri', 1): 157,\n",
       " ('offer', 1): 174,\n",
       " ('750', 1): 73,\n",
       " ('anytim', 1): 50,\n",
       " ('camcord', 1): 60,\n",
       " ('08000930705', 1): 69,\n",
       " ('repres', 1): 44,\n",
       " ('169', 1): 8,\n",
       " ('6031', 1): 8,\n",
       " ('10am9pm', 1): 8,\n",
       " ('1st', 1): 130,\n",
       " ('entri', 1): 102,\n",
       " ('textpod', 1): 7,\n",
       " ('å£250', 1): 53,\n",
       " ('everi', 1): 138,\n",
       " ('wk', 1): 72,\n",
       " ('pod', 1): 13,\n",
       " ('84128', 1): 10,\n",
       " ('tsc', 1): 62,\n",
       " ('wwwtextpodnet', 1): 7,\n",
       " ('custcar', 1): 25,\n",
       " ('08712405020', 1): 23,\n",
       " ('congratul', 1): 81,\n",
       " ('award', 1): 286,\n",
       " ('cd', 1): 68,\n",
       " ('125gift', 1): 21,\n",
       " ('wkli', 1): 65,\n",
       " ('draw', 1): 182,\n",
       " ('music', 1): 85,\n",
       " ('87066', 1): 59,\n",
       " ('sub', 1): 46,\n",
       " ('weekli', 1): 102,\n",
       " ('ringtoneget', 1): 11,\n",
       " ('freesend', 1): 11,\n",
       " ('subpoli', 1): 16,\n",
       " ('816183', 1): 11,\n",
       " ('weekstop', 1): 11,\n",
       " ('sms08718727870', 1): 11,\n",
       " ('prizeto', 1): 4,\n",
       " ('yr', 1): 57,\n",
       " ('09066649731from', 1): 5,\n",
       " ('complimentari', 1): 55,\n",
       " ('ibiza', 1): 21,\n",
       " ('å£10000', 1): 27,\n",
       " ('434', 1): 15,\n",
       " ('sk3', 1): 15,\n",
       " ('8wp', 1): 15,\n",
       " ('ringtonek', 1): 6,\n",
       " ('84484', 1): 6,\n",
       " ('competit', 1): 14,\n",
       " ('å£1450', 1): 20,\n",
       " ('09050002311', 1): 12,\n",
       " ('b4280703', 1): 12,\n",
       " ('tcsstop', 1): 20,\n",
       " ('sm', 1): 108,\n",
       " ('08718727868', 1): 12,\n",
       " ('dear', 1): 64,\n",
       " ('final', 1): 67,\n",
       " ('gr8', 1): 14,\n",
       " ('str8', 1): 2,\n",
       " ('8007', 1): 89,\n",
       " ('classic', 1): 2,\n",
       " ('poli', 1): 87,\n",
       " ('nokia150p', 1): 2,\n",
       " ('poly200p', 1): 2,\n",
       " ('1', 1): 135,\n",
       " ('08715205273', 1): 4,\n",
       " ('today', 1): 159,\n",
       " ('09058094565', 1): 13,\n",
       " ('land', 1): 73,\n",
       " ('valid', 1): 107,\n",
       " ('12hr', 1): 73,\n",
       " ('rgent', 1): 7,\n",
       " ('uu', 1): 11,\n",
       " ('å£1250', 1): 11,\n",
       " ('09071512433', 1): 11,\n",
       " ('b4', 1): 29,\n",
       " ('050703', 1): 11,\n",
       " ('tcsbcm4235wc1n3xx', 1): 11,\n",
       " ('callcost', 1): 11,\n",
       " ('mobilesvari', 1): 11,\n",
       " ('maxå£7', 1): 11,\n",
       " ('50', 1): 18,\n",
       " ('footbal', 1): 7,\n",
       " ('back', 1): 74,\n",
       " ('tv', 1): 26,\n",
       " ('sky', 1): 14,\n",
       " ('gamestar', 1): 7,\n",
       " ('activ', 1): 30,\n",
       " ('play', 1): 78,\n",
       " ('å£250k', 1): 7,\n",
       " ('dream', 1): 9,\n",
       " ('team', 1): 11,\n",
       " ('score', 1): 12,\n",
       " ('start', 1): 51,\n",
       " ('saturday', 1): 16,\n",
       " ('regist', 1): 22,\n",
       " ('nowski', 1): 7,\n",
       " ('88088', 1): 7,\n",
       " ('ac', 1): 24,\n",
       " ('sun0819', 1): 10,\n",
       " ('post', 1): 29,\n",
       " ('helloy', 1): 10,\n",
       " ('seem', 1): 10,\n",
       " ('cool', 1): 10,\n",
       " ('subscript', 1): 21,\n",
       " ('å£5month', 1): 7,\n",
       " ('confirm', 1): 7,\n",
       " ('ye', 1): 55,\n",
       " ('updatenow', 1): 9,\n",
       " ('sonyericsson', 1): 21,\n",
       " ('bluetooth', 1): 36,\n",
       " ('doubl', 1): 77,\n",
       " ('1000', 1): 39,\n",
       " ('08000839402', 1): 61,\n",
       " ('call2optoutf4q', 1): 5,\n",
       " ('spjanuari', 1): 2,\n",
       " ('male', 1): 9,\n",
       " ('sale', 1): 15,\n",
       " ('gay', 1): 13,\n",
       " ('cheaper', 1): 4,\n",
       " ('08709222922', 1): 4,\n",
       " ('15pmin', 1): 4,\n",
       " ('cheap', 1): 11,\n",
       " ('78pmin', 1): 4,\n",
       " ('peak', 1): 4,\n",
       " ('08712460324', 1): 15,\n",
       " ('10pmin', 1): 26,\n",
       " ('sexi', 1): 60,\n",
       " ('cum', 1): 23,\n",
       " ('im', 1): 49,\n",
       " ('wet', 1): 7,\n",
       " ('warm', 1): 12,\n",
       " ('readi', 1): 24,\n",
       " ('fun', 1): 34,\n",
       " ('150p', 1): 81,\n",
       " ('vat', 1): 5,\n",
       " ('cancel', 1): 17,\n",
       " ('well', 1): 28,\n",
       " ('done', 1): 12,\n",
       " ('england', 1): 30,\n",
       " ('offici', 1): 17,\n",
       " ('flag', 1): 28,\n",
       " ('yer', 1): 12,\n",
       " ('84199', 1): 12,\n",
       " ('optout', 1): 37,\n",
       " ('eng', 1): 12,\n",
       " ('box39822', 1): 12,\n",
       " ('w111wx', 1): 12,\n",
       " ('å£150', 1): 95,\n",
       " ('pdatenow', 1): 6,\n",
       " ('tariff', 1): 25,\n",
       " ('call2optoutyhl', 1): 6,\n",
       " ('last', 1): 53,\n",
       " ('worth', 1): 45,\n",
       " ('shop', 1): 61,\n",
       " ('85023', 1): 30,\n",
       " ('savamob', 1): 53,\n",
       " ('c', 1): 128,\n",
       " ('pobox84', 1): 28,\n",
       " ('m263uz', 1): 15,\n",
       " ('å£300', 1): 30,\n",
       " ('good', 1): 62,\n",
       " ('luck', 1): 30,\n",
       " ('place', 1): 28,\n",
       " ('28th', 1): 8,\n",
       " ('feb', 1): 8,\n",
       " ('06', 1): 8,\n",
       " ('remov', 1): 25,\n",
       " ('87239', 1): 25,\n",
       " ('08708034412', 1): 13,\n",
       " ('freephon', 1): 33,\n",
       " ('0808', 1): 22,\n",
       " ('145', 1): 22,\n",
       " ('4742', 1): 22,\n",
       " ('9am11pm', 1): 22,\n",
       " ('germani', 1): 12,\n",
       " ('penc', 1): 13,\n",
       " ('minut', 1): 59,\n",
       " ('fix', 1): 9,\n",
       " ('via', 1): 11,\n",
       " ('access', 1): 30,\n",
       " ('0844', 1): 9,\n",
       " ('861', 1): 9,\n",
       " ('85', 1): 18,\n",
       " ('prepay', 1): 9,\n",
       " ('wwwtelediscountcouk', 1): 7,\n",
       " ('tddnewsletteremc1couk', 1): 6,\n",
       " ('game', 1): 114,\n",
       " ('thedailydraw', 1): 6,\n",
       " ('helen', 1): 6,\n",
       " ('dozen', 1): 6,\n",
       " ('great', 1): 47,\n",
       " ('prizeswith', 1): 6,\n",
       " ('voicemail', 1): 9,\n",
       " ('08719181503', 1): 4,\n",
       " ('term', 1): 42,\n",
       " ('condit', 1): 16,\n",
       " ('visit', 1): 29,\n",
       " ('www07781482378com', 1): 9,\n",
       " ('sunshin', 1): 22,\n",
       " ('quiz', 1): 39,\n",
       " ('super', 1): 10,\n",
       " ('soni', 1): 22,\n",
       " ('dvd', 1): 21,\n",
       " ('record', 1): 16,\n",
       " ('cannam', 1): 2,\n",
       " ('capit', 1): 2,\n",
       " ('australia', 1): 2,\n",
       " ('mquiz', 1): 2,\n",
       " ('82277', 1): 12,\n",
       " ('b', 1): 39,\n",
       " ('5903', 1): 5,\n",
       " ('09064019788', 1): 5,\n",
       " ('box42wr29c', 1): 5,\n",
       " ('six', 1): 12,\n",
       " ('20000', 1): 9,\n",
       " ('pound', 1): 93,\n",
       " ('csh11', 1): 9,\n",
       " ('87575', 1): 19,\n",
       " ('cost', 1): 100,\n",
       " ('150pday', 1): 9,\n",
       " ('6day', 1): 9,\n",
       " ('tsandc', 1): 9,\n",
       " ('hl', 1): 31,\n",
       " ('info', 1): 44,\n",
       " ('gr8prize', 1): 4,\n",
       " ('comp', 1): 42,\n",
       " ('8800', 1): 4,\n",
       " ('psp', 1): 4,\n",
       " ('wktxt', 1): 4,\n",
       " ('80878', 1): 12,\n",
       " ('httpwwwgr8prizescom', 1): 4,\n",
       " ('08715705022', 1): 16,\n",
       " ('valu', 1): 52,\n",
       " ('receivea', 1): 13,\n",
       " ('å£900', 1): 34,\n",
       " ('reward', 1): 48,\n",
       " ('09061701461', 1): 13,\n",
       " ('code', 1): 116,\n",
       " ('kl341', 1): 13,\n",
       " ('hour', 1): 24,\n",
       " ('freemsg', 1): 45,\n",
       " ('fanci', 1): 29,\n",
       " ('flirt', 1): 26,\n",
       " ('date', 1): 100,\n",
       " ('fastest', 1): 13,\n",
       " ('grow', 1): 13,\n",
       " ('rcvd', 1): 29,\n",
       " ('25p', 1): 36,\n",
       " ('83021', 1): 8,\n",
       " ('mr', 1): 9,\n",
       " ('foley', 1): 9,\n",
       " ('excit', 1): 19,\n",
       " ('soon', 1): 11,\n",
       " ('keep', 1): 22,\n",
       " ('eye', 1): 9,\n",
       " ('wwwwin82050couk', 1): 9,\n",
       " ('girl', 1): 35,\n",
       " ('bloke', 1): 5,\n",
       " ('name', 1): 63,\n",
       " ('age', 1): 32,\n",
       " ('eg', 1): 53,\n",
       " ('zoe', 1): 5,\n",
       " ('chosen', 1): 20,\n",
       " ('å£350', 1): 49,\n",
       " ('pl', 1): 53,\n",
       " ('09066364311', 1): 13,\n",
       " ('weekend', 1): 45,\n",
       " ('09061701851', 1): 7,\n",
       " ('k61', 1): 7,\n",
       " ('12hour', 1): 7,\n",
       " ('3510i', 1): 21,\n",
       " ('deliv', 1): 16,\n",
       " ('tomorrow', 1): 33,\n",
       " ('200', 1): 17,\n",
       " ('eastend', 1): 11,\n",
       " ('flower', 1): 17,\n",
       " ('dot', 1): 11,\n",
       " ('compar', 1): 11,\n",
       " ('violet', 1): 11,\n",
       " ('e', 1): 28,\n",
       " ('tulip', 1): 11,\n",
       " ('f', 1): 36,\n",
       " ('lili', 1): 11,\n",
       " ('84025', 1): 13,\n",
       " ('å£100', 1): 95,\n",
       " ('wkent150p16', 1): 11,\n",
       " ('someon', 1): 36,\n",
       " ('know', 1): 78,\n",
       " ('ask', 1): 15,\n",
       " ('cant', 1): 10,\n",
       " ('guess', 1): 17,\n",
       " ('09058091854', 1): 4,\n",
       " ('box385', 1): 4,\n",
       " ('m6', 1): 4,\n",
       " ('6wu', 1): 4,\n",
       " ('donat', 1): 8,\n",
       " ('unicef', 1): 4,\n",
       " ('asian', 1): 4,\n",
       " ('tsunami', 1): 4,\n",
       " ('disast', 1): 4,\n",
       " ('support', 1): 9,\n",
       " ('fund', 1): 4,\n",
       " ('864233', 1): 4,\n",
       " ('ad', 1): 14,\n",
       " ('bill', 1): 28,\n",
       " ('twink', 1): 4,\n",
       " ('bear', 1): 4,\n",
       " ('scalli', 1): 4,\n",
       " ('skin', 1): 4,\n",
       " ('jock', 1): 4,\n",
       " ('dont', 1): 80,\n",
       " ('miss', 1): 37,\n",
       " ('08712466669', 1): 4,\n",
       " ('08712460324nat', 1): 4,\n",
       " ('rp176781', 1): 4,\n",
       " ('wwwregalportfoliocouk', 1): 4,\n",
       " ('08717205546', 1): 4,\n",
       " ('q', 1): 10,\n",
       " ('countri', 1): 10,\n",
       " ('liverpool', 1): 8,\n",
       " ('mid', 1): 3,\n",
       " ('ansr', 1): 10,\n",
       " ('sptyron', 1): 10,\n",
       " ('08712402972', 1): 3,\n",
       " ('immedi', 1): 14,\n",
       " ('wait', 1): 63,\n",
       " ('å£750', 1): 6,\n",
       " ('easi', 1): 52,\n",
       " ('087187272008', 1): 6,\n",
       " ('now1', 1): 6,\n",
       " ('10p', 1): 67,\n",
       " ('btnationalr', 1): 39,\n",
       " ('1month', 1): 5,\n",
       " ('unlimit', 1): 43,\n",
       " ('smartcal', 1): 5,\n",
       " ('68866', 1): 5,\n",
       " ('subscriptn3gbpwk', 1): 5,\n",
       " ('help', 1): 87,\n",
       " ('08448714184', 1): 5,\n",
       " ('stoptxt', 1): 5,\n",
       " ('landlineonli', 1): 5,\n",
       " ('voda', 1): 21,\n",
       " ('end', 1): 97,\n",
       " ('5226', 1): 1,\n",
       " ('350', 1): 6,\n",
       " ('hava', 1): 1,\n",
       " ('match', 1): 52,\n",
       " ('08712300220', 1): 25,\n",
       " ('quot', 1): 25,\n",
       " ('1131', 1): 1,\n",
       " ('standard', 1): 28,\n",
       " ('app', 1): 19,\n",
       " ('å£200', 1): 49,\n",
       " ('even', 1): 27,\n",
       " ('cashto', 1): 11,\n",
       " ('08000407165', 1): 11,\n",
       " ('getstop', 1): 11,\n",
       " ('88222', 1): 11,\n",
       " ('php', 1): 11,\n",
       " ('1225', 1): 7,\n",
       " ('å£50award', 1): 7,\n",
       " ('3100', 1): 13,\n",
       " ('08714712394', 1): 3,\n",
       " ('10am7pm', 1): 16,\n",
       " ('inclus', 1): 18,\n",
       " ('goto', 1): 24,\n",
       " ('wwwcomuknet', 1): 18,\n",
       " ('login', 1): 18,\n",
       " ('3qxj9', 1): 17,\n",
       " ('unsubscrib', 1): 73,\n",
       " ('extra', 1): 26,\n",
       " ('08702840625comuk', 1): 15,\n",
       " ('220cm2', 1): 15,\n",
       " ('9ae', 1): 17,\n",
       " ('08714712379', 1): 4,\n",
       " ('hvae', 1): 3,\n",
       " ('09061701444', 1): 3,\n",
       " ('24', 1): 6,\n",
       " ('acl03530150pm', 1): 8,\n",
       " ('heard', 1): 16,\n",
       " ('u4', 1): 16,\n",
       " ('rude', 1): 12,\n",
       " ('privat', 1): 66,\n",
       " ('01223585334', 1): 12,\n",
       " ('wan', 1): 47,\n",
       " ('2c', 1): 12,\n",
       " ('gettin', 1): 12,\n",
       " ('shag', 1): 13,\n",
       " ('pix', 1): 15,\n",
       " ('8552', 1): 24,\n",
       " ('2end', 1): 12,\n",
       " ('sam', 1): 16,\n",
       " ('rayman', 1): 7,\n",
       " ('golf', 1): 7,\n",
       " ('o2', 1): 27,\n",
       " ('arcad', 1): 38,\n",
       " ('set', 1): 23,\n",
       " ('save', 1): 17,\n",
       " ('activ8', 1): 7,\n",
       " ('press', 1): 19,\n",
       " ('0', 1): 19,\n",
       " ('key', 1): 7,\n",
       " ('termsappli', 1): 7,\n",
       " ('07734396839', 1): 10,\n",
       " ('ibh', 1): 10,\n",
       " ('loyalti', 1): 32,\n",
       " ('nokia6600', 1): 10,\n",
       " ('å£10', 1): 24,\n",
       " ('txtauctiontxt', 1): 10,\n",
       " ('wordstart', 1): 10,\n",
       " ('no81151', 1): 10,\n",
       " ('now4t', 1): 10,\n",
       " ('no1', 1): 45,\n",
       " ('tell', 1): 88,\n",
       " ('mate', 1): 57,\n",
       " ('wwwgetzedcouk', 1): 44,\n",
       " ('pobox', 1): 59,\n",
       " ('36504', 1): 37,\n",
       " ('w4', 1): 7,\n",
       " ('5wq', 1): 7,\n",
       " ('norm', 1): 12,\n",
       " ('150ptone', 1): 29,\n",
       " ('youv', 1): 15,\n",
       " ('tkt', 1): 13,\n",
       " ('euro2004', 1): 14,\n",
       " ('cup', 1): 19,\n",
       " ('å£800', 1): 32,\n",
       " ('09058099801', 1): 6,\n",
       " ('b4190604', 1): 6,\n",
       " ('7876150ppm', 1): 6,\n",
       " ('0870k', 1): 9,\n",
       " ('spook', 1): 17,\n",
       " ('halloween', 1): 11,\n",
       " ('logo', 1): 20,\n",
       " ('plu', 1): 32,\n",
       " ('eeri', 1): 20,\n",
       " ('card', 1): 15,\n",
       " ('zed', 1): 26,\n",
       " ('08701417012150p', 1): 6,\n",
       " ('logop', 1): 11,\n",
       " ('link', 1): 26,\n",
       " ('pictur', 1): 3,\n",
       " ('also', 1): 9,\n",
       " ('use', 1): 38,\n",
       " ('httpalto18coukwavewaveaspo44345', 1): 3,\n",
       " ('summer', 1): 25,\n",
       " ('singl', 1): 21,\n",
       " ('area', 1): 28,\n",
       " ('help08714742804', 1): 4,\n",
       " ('club', 1): 69,\n",
       " ('mix', 1): 15,\n",
       " ('mytonecomenjoy', 1): 6,\n",
       " ('html', 1): 6,\n",
       " ('gbp450week', 1): 6,\n",
       " ('mfl', 1): 6,\n",
       " ('knicker', 1): 4,\n",
       " ('beg', 1): 4,\n",
       " ('like', 1): 56,\n",
       " ('01223585236', 1): 4,\n",
       " ('xx', 1): 12,\n",
       " ('luv', 1): 19,\n",
       " ('nikiyu4net', 1): 4,\n",
       " ('087147123779am7pm', 1): 8,\n",
       " ('continu', 1): 5,\n",
       " ('question', 1): 42,\n",
       " ('enter', 1): 50,\n",
       " ('in2', 1): 5,\n",
       " ('presid', 1): 5,\n",
       " ('an', 1): 30,\n",
       " ('80082', 1): 9,\n",
       " ('profession', 1): 6,\n",
       " ('sport', 1): 32,\n",
       " ('tiger', 1): 6,\n",
       " ('wood', 1): 6,\n",
       " ('449071512431', 1): 4,\n",
       " ('money', 1): 17,\n",
       " ('wine', 1): 1,\n",
       " ('946', 1): 1,\n",
       " ('wot', 1): 1,\n",
       " ('ithi', 1): 3,\n",
       " ('first', 1): 26,\n",
       " ('creat', 1): 3,\n",
       " ('web', 1): 10,\n",
       " ('page', 1): 3,\n",
       " ('wwwasjesuscom', 1): 3,\n",
       " ('read', 1): 3,\n",
       " ('wrote', 1): 3,\n",
       " ('opinion', 1): 3,\n",
       " ('09050003091', 1): 9,\n",
       " ('c52', 1): 9,\n",
       " ('decemb', 1): 24,\n",
       " ('08002986906', 1): 20,\n",
       " ('ton', 1): 4,\n",
       " ('babe', 1): 25,\n",
       " ('hunk', 1): 4,\n",
       " ('straight', 1): 6,\n",
       " ('httpgotbabescouk', 1): 4,\n",
       " ('09061743810', 1): 5,\n",
       " ('abta', 1): 12,\n",
       " ('tenerif', 1): 36,\n",
       " ('5000', 1): 15,\n",
       " ('326', 1): 8,\n",
       " ('cw25wx', 1): 16,\n",
       " ('ppm', 1): 17,\n",
       " ('remind', 1): 11,\n",
       " ('250', 1): 22,\n",
       " ('detail', 1): 31,\n",
       " ('hous', 1): 7,\n",
       " ('postcod', 1): 16,\n",
       " ('let', 1): 21,\n",
       " ('150pmsg', 1): 67,\n",
       " ('hgsuite3422landsroww1j6hl', 1): 13,\n",
       " ('spanish', 1): 7,\n",
       " ('09050000332', 1): 3,\n",
       " ('rstm', 1): 8,\n",
       " ('sw7', 1): 8,\n",
       " ('3', 1): 101,\n",
       " ('msgwe', 1): 6,\n",
       " ('mistak', 1): 6,\n",
       " ('shortcod', 1): 6,\n",
       " ('83332pleas', 1): 6,\n",
       " ('08081263000', 1): 6,\n",
       " ('refundedthi', 1): 6,\n",
       " ('hottest', 1): 2,\n",
       " ('89555', 1): 7,\n",
       " ('textoper', 1): 7,\n",
       " ('g696ga', 1): 2,\n",
       " ('80182', 1): 10,\n",
       " ('std', 1): 39,\n",
       " ('08452810073', 1): 10,\n",
       " ('goal', 1): 15,\n",
       " ('arsen', 1): 16,\n",
       " ('henri', 1): 10,\n",
       " ('7', 1): 7,\n",
       " ('v', 1): 19,\n",
       " ('simpl', 1): 5,\n",
       " ('shot', 1): 5,\n",
       " ('6', 1): 19,\n",
       " ('yard', 1): 5,\n",
       " ('pas', 1): 28,\n",
       " ('bergkamp', 1): 5,\n",
       " ('give', 1): 27,\n",
       " ('margin', 1): 5,\n",
       " ('78', 1): 5,\n",
       " ('7634', 1): 2,\n",
       " ('7684', 1): 2,\n",
       " ('09064017295', 1): 5,\n",
       " ('k52', 1): 14,\n",
       " ('pm', 1): 6,\n",
       " ('brand', 1): 21,\n",
       " ('7250', 1): 13,\n",
       " ('roww1j6hl', 1): 23,\n",
       " ('import', 1): 40,\n",
       " ('inform', 1): 43,\n",
       " ('user', 1): 35,\n",
       " ('0796xxxxxx', 1): 3,\n",
       " ('day2', 1): 3,\n",
       " ('httpwwwurawinnercom', 1): 29,\n",
       " ('there', 1): 16,\n",
       " ('fantast', 1): 31,\n",
       " ('prizeawait', 1): 3,\n",
       " ('09058095201', 1): 5,\n",
       " ('deliveri', 1): 79,\n",
       " ('dept', 1): 1,\n",
       " ('expir', 1): 58,\n",
       " ('13404', 1): 1,\n",
       " ('08717507382', 1): 1,\n",
       " ('08714712412', 1): 3,\n",
       " ('announc', 1): 16,\n",
       " ('premier', 1): 5,\n",
       " ('block', 1): 3,\n",
       " ('breaker', 1): 3,\n",
       " ('come', 1): 20,\n",
       " ('delux', 1): 3,\n",
       " ('format', 1): 3,\n",
       " ('featur', 1): 3,\n",
       " ('graphic', 1): 3,\n",
       " ('tmobil', 1): 10,\n",
       " ('buy', 1): 15,\n",
       " ('å£5', 1): 3,\n",
       " ('bbdelux', 1): 3,\n",
       " ('challeng', 1): 3,\n",
       " ('gnarl', 1): 6,\n",
       " ('barkley', 1): 6,\n",
       " ('crazi', 1): 26,\n",
       " ('total', 1): 12,\n",
       " ('right', 1): 17,\n",
       " ('bank', 1): 9,\n",
       " ('granit', 1): 9,\n",
       " ('issu', 1): 9,\n",
       " ('strongbuy', 1): 9,\n",
       " ('explos', 1): 9,\n",
       " ('pick', 1): 25,\n",
       " ('member', 1): 37,\n",
       " ('300', 1): 21,\n",
       " ('nasdaq', 1): 9,\n",
       " ('symbol', 1): 9,\n",
       " ('cdgt', 1): 9,\n",
       " ('87077', 1): 39,\n",
       " ('kick', 1): 8,\n",
       " ('season', 1): 5,\n",
       " ('2wk', 1): 5,\n",
       " ('news', 1): 41,\n",
       " ('villa', 1): 5,\n",
       " ('4u', 1): 20,\n",
       " ('rpli', 1): 22,\n",
       " ('titl', 1): 22,\n",
       " ('dracula', 1): 9,\n",
       " ('ghost', 1): 9,\n",
       " ('addamsfa', 1): 9,\n",
       " ('munster', 1): 9,\n",
       " ('exorcist', 1): 9,\n",
       " ('twilight', 1): 9,\n",
       " ('pobox36504w45wq', 1): 26,\n",
       " ('lion', 1): 6,\n",
       " ('lionm', 1): 6,\n",
       " ('mono', 1): 15,\n",
       " ('lionp', 1): 6,\n",
       " ('wwwringtonescouk', 1): 14,\n",
       " ('origin', 1): 14,\n",
       " ('n', 1): 36,\n",
       " ('best', 1): 34,\n",
       " ('3gbp', 1): 14,\n",
       " ('advis', 1): 14,\n",
       " ('follow', 1): 45,\n",
       " ('recent', 1): 21,\n",
       " ('review', 1): 16,\n",
       " ('å£1500', 1): 21,\n",
       " ('09066364589', 1): 11,\n",
       " ('trip', 1): 15,\n",
       " ('eurodisinc', 1): 8,\n",
       " ('trav', 1): 8,\n",
       " ('acoentry41', 1): 8,\n",
       " ('di', 1): 8,\n",
       " ('87121', 1): 15,\n",
       " ('186å£150morefrmmob', 1): 8,\n",
       " ('shracomorsglsuplt10', 1): 8,\n",
       " ('ls1', 1): 8,\n",
       " ('3aj', 1): 8,\n",
       " ('09050000878', 1): 2,\n",
       " ('pobox45w2tg150p', 1): 6,\n",
       " ('big', 1): 9,\n",
       " ('brother', 1): 4,\n",
       " ('alert', 1): 14,\n",
       " ('comput', 1): 20,\n",
       " ('10k', 1): 9,\n",
       " ('09064018838', 1): 4,\n",
       " ('cro1327', 1): 4,\n",
       " ('vari', 1): 19,\n",
       " ('mandi', 1): 7,\n",
       " ('sullivan', 1): 7,\n",
       " ('hotmix', 1): 7,\n",
       " ('fmyou', 1): 7,\n",
       " ('å£500000', 1): 7,\n",
       " ('easter', 1): 7,\n",
       " ('drawpleas', 1): 7,\n",
       " ('telephon', 1): 7,\n",
       " ('09041940223', 1): 7,\n",
       " ('290305', 1): 7,\n",
       " ('transfer', 1): 7,\n",
       " ('el', 1): 7,\n",
       " ('2003', 1): 42,\n",
       " ('account', 1): 63,\n",
       " ('statement', 1): 54,\n",
       " ('800', 1): 40,\n",
       " ('unredeem', 1): 52,\n",
       " ('sim', 1): 19,\n",
       " ('point', 1): 52,\n",
       " ('08718738001', 1): 10,\n",
       " ('identifi', 1): 52,\n",
       " ('49557', 1): 6,\n",
       " ('261104', 1): 6,\n",
       " ('gent', 1): 9,\n",
       " ('09064012160', 1): 9,\n",
       " ('somebodi', 1): 6,\n",
       " ('secretli', 1): 6,\n",
       " ('na', 1): 35,\n",
       " ('09065394973', 1): 1,\n",
       " ('datebox1282essexcm61xn', 1): 6,\n",
       " ('150pmin', 1): 9,\n",
       " ('80488', 1): 9,\n",
       " ('31', 1): 4,\n",
       " ('2005', 1): 11,\n",
       " ('agent', 1): 4,\n",
       " ('load', 1): 4,\n",
       " ('goodi', 1): 4,\n",
       " ('mat', 1): 4,\n",
       " ('87021', 1): 16,\n",
       " ('09066350750', 1): 10,\n",
       " ('10000', 1): 10,\n",
       " ('09053750005', 1): 8,\n",
       " ('310303', 1): 8,\n",
       " ('08718725756', 1): 8,\n",
       " ('140ppm', 1): 8,\n",
       " ('10', 1): 22,\n",
       " ('cameravideo', 1): 7,\n",
       " ('å£', 1): 4,\n",
       " ('textsweekend', 1): 4,\n",
       " ('callback', 1): 9,\n",
       " ('orno', 1): 4,\n",
       " ('hmv', 1): 25,\n",
       " ('genuin', 1): 8,\n",
       " ('answer', 1): 24,\n",
       " ('infowww100percentrealcom', 1): 8,\n",
       " ('2u', 1): 2,\n",
       " ('breathe1', 1): 2,\n",
       " ('crazyin', 1): 2,\n",
       " ('sleepingwith', 1): 2,\n",
       " ('finest', 1): 2,\n",
       " ('ymca', 1): 2,\n",
       " ('getzedcouk', 1): 2,\n",
       " ('pobox365o4w45wq', 1): 2,\n",
       " ('300p', 1): 4,\n",
       " ('messagethank', 1): 3,\n",
       " ('150pmsgrcvd', 1): 3,\n",
       " ('skip', 1): 3,\n",
       " ('customercar', 1): 3,\n",
       " ('08718726270', 1): 6,\n",
       " ...}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Run this cell to get an idea about the corpus of words and their occurrence along with labels. \n",
    "## In this, we are computing the frequency of occurrence of word given that a message is 'spam'.\n",
    "## Similarly, we also compute the frequence of occurence of word given that a message is 'ham'.\n",
    "freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759c24bc",
   "metadata": {},
   "source": [
    "## Training the Naive Bayes Model: (20 points)\n",
    "\n",
    "Now we are in the training phase of the Naive Bayes algorithm. In this cell, take a look at the ways to calculate the log likelihood and log prior values as these are important for testing in the next few cells. \n",
    "\n",
    "Also calculate the frequency of occurrence of words where the output is spam. In the same way, calculate the word frequency count using the above functions in order to compute the log likelihood.\n",
    "\n",
    "Return the logprior and loglikelihood output by the model from this function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7f280e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(freqs, train_x, train_y):\n",
    "    '''\n",
    "    Input:\n",
    "        freqs: dictionary from (word, label) to how often the word appears\n",
    "        train_x: a list of messages\n",
    "        train_y: a list of labels correponding to the messages (0,1)\n",
    "    Output:\n",
    "        logprior: the log prior. (equation 3 above)\n",
    "        loglikelihood: the log likelihood of you Naive bayes equation. (equation 6 above)\n",
    "    '''\n",
    "    loglikelihood = {}\n",
    "    logprior = 0\n",
    "\n",
    "\n",
    "    # calculate V, the number of unique words in the vocabulary\n",
    "    vocab = set([key[0] for key in freqs])\n",
    "    V = len(vocab)\n",
    "\n",
    "    # calculate num_pos and num_neg - the total number of positive and negative words for all documents\n",
    "    num_pos = num_neg = 0\n",
    "    for pair in freqs.keys():\n",
    "        # if the label is positive (greater than zero)\n",
    "        if pair[1]==1:\n",
    "            # Increment the number of positive words by the count for this (word, label) pair\n",
    "            num_pos+=freqs[pair]\n",
    "        # else, the label is negative\n",
    "        else:\n",
    "            # increment the number of negative words by the count for this (word,label) pair\n",
    "            num_neg +=freqs[pair]\n",
    "\n",
    "    # Calculate num_doc, the number of documents\n",
    "    num_doc = len(train_x)\n",
    "\n",
    "    # Calculate D_pos, the number of positive documents \n",
    "    pos_num_docs = train_y.sum()\n",
    "\n",
    "    # Calculate D_neg, the number of negative documents \n",
    "    neg_num_docs = num_doc-pos_num_docs\n",
    "\n",
    "    # Calculate logprior\n",
    "    logprior = np.log(pos_num_docs)-np.log(neg_num_docs)\n",
    "\n",
    "    # For each word in the vocabulary...\n",
    "    for word in vocab:\n",
    "        # get the positive and negative frequency of the word\n",
    "        freq_pos=freq_neg=0\n",
    "        if ((word,1) in freqs.keys()) :\n",
    "            freq_pos = freqs[(word,1)]\n",
    "        if((word, 0) in freqs.keys()):\n",
    "            freq_neg = freqs[(word, 0)]\n",
    "\n",
    "        # calculate the probability that each word is positive, and negative\n",
    "        #With smoothing\n",
    "        p_w_pos = (freq_pos + 1)/(num_pos + V)\n",
    "        p_w_neg = (freq_neg + 1)/(num_neg + V)\n",
    "\n",
    "        # calculate the log likelihood of the word\n",
    "        loglikelihood[word] = np.log(p_w_pos) - np.log(p_w_neg)\n",
    "\n",
    "\n",
    "    return logprior, loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1561d892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "6577\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# You do not have to input any code in this cell, but it is relevant to grading, so please do not change anything\n",
    "logprior, loglikelihood = train_naive_bayes(freqs, X_train, y_train)\n",
    "print(logprior)\n",
    "print(len(loglikelihood))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d9c882",
   "metadata": {},
   "source": [
    "### Expected Output \n",
    "\n",
    "0.0 <br>\n",
    "6763"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b51303",
   "metadata": {},
   "source": [
    "## Implementing Naive Bayes Predict Function: (15 points)\n",
    "\n",
    "It is now time to make our prediction as to whether a given message is spam or ham respectively. \n",
    "\n",
    "After adding the log likelihood values, ensure that the output is 1 (spam) if the sum of the log likelihood value is greater than 0 and 0 (ham) if the sum of the log likelihood is less than or equal to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b692c2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 4 CELL\n",
    "\n",
    "def naive_bayes_predict(message, logprior, loglikelihood):\n",
    "    '''\n",
    "    Params:\n",
    "        message: a string\n",
    "        logprior: a number\n",
    "        loglikelihood: a dictionary of words mapping to numbers\n",
    "    Return:\n",
    "        total_prob: the sum of all the loglikelihoods of each word in the message (if found in the dictionary) + logprior (a number)\n",
    "\n",
    "    '''\n",
    "    \n",
    "     # process the message to get a list of words\n",
    "    word_l = clean_message(message)\n",
    "\n",
    "    # initialize probability to zero\n",
    "    total_prob = 0\n",
    "\n",
    "    # add the logprior\n",
    "    total_prob = total_prob + logprior\n",
    "\n",
    "    for word in word_l:\n",
    "\n",
    "        # check if the word exists in the loglikelihood dictionary\n",
    "        if word in loglikelihood.keys():\n",
    "            # add the log likelihood of that word to the probability\n",
    "            total_prob = total_prob + loglikelihood[word]\n",
    "        if(total_prob>0):\n",
    "            total_prob = 1\n",
    "        else:\n",
    "            total_prob = 0\n",
    "\n",
    "    return total_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b170333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected output is 0\n"
     ]
    }
   ],
   "source": [
    "# You do not have to input any code in this cell, but it is relevant to grading, so please do not change anything\n",
    "\n",
    "# Experiment with your own message.\n",
    "my_message = 'She smiled'\n",
    "p = naive_bayes_predict(my_message, logprior, loglikelihood)\n",
    "print('The expected output is', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6242708f",
   "metadata": {},
   "source": [
    "### Expected Output :\n",
    "The expected output is 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4eeb71",
   "metadata": {},
   "source": [
    "## Implementing Naive Bayes Test function: (15 points)\n",
    "\n",
    "In this function, implement the previous functions such as naive_bayes_predict to get the predictions for the test set. \n",
    "\n",
    "In addition to this, the function should return the total number of messages that it correctly classified as 'spam' or 'ham'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66a511e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def test_naive_bayes(test_x, test_y, logprior, loglikelihood):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        test_x: A list of messages\n",
    "        test_y: the corresponding labels for the list of messages\n",
    "        logprior: the logprior\n",
    "        loglikelihood: a dictionary with the loglikelihoods for each word\n",
    "    Output:\n",
    "        accuracy: (# of messages classified correctly)/(total # of message)\n",
    "    \"\"\"\n",
    "    accuracy = 0\n",
    "    y_hats=[]\n",
    "\n",
    "    for message in test_x:\n",
    "        # if the prediction is > 0\n",
    "        if naive_bayes_predict(message, logprior, loglikelihood)>0:\n",
    "            # the predicted class is 1\n",
    "            y_hat_i = 1\n",
    "        else:\n",
    "            # otherwise the predicted class is 0\n",
    "            y_hat_i = 0\n",
    "\n",
    "        # append the predicted class to the list y_hats\n",
    "        y_hats.append(y_hat_i)\n",
    "        \n",
    "\n",
    "    # error is the average of the absolute values of the differences between y_hats and test_y\n",
    "    error = abs(y_hats-test_y).mean()\n",
    "\n",
    "    accuracy=sum(y_hats == test_y)/len(test_y)\n",
    "\n",
    "\n",
    "    return print(f\"Error is {error} and accuracy is {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6bcc71a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error is 0.11452054794520548 and accuracy is 0.8854794520547945\n"
     ]
    }
   ],
   "source": [
    "test_naive_bayes(X_test, y_test, logprior, loglikelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a9c5d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get an offer -> 1.00\n",
      "get the latest movie review -> 1.00\n",
      "order iphone -> 0.00\n",
      "I am on a meeting -> 0.00\n"
     ]
    }
   ],
   "source": [
    "# For grading purpose only\n",
    "# You do not have to input any code in this cell, but it is relevant to grading, so please do not change anything\n",
    "\n",
    "# Run this cell to test your function\n",
    "for message in ['get an offer', 'get the latest movie review', 'order iphone', 'I am on a meeting']:\n",
    "    # print( '%s -> %f' % (message, naive_bayes_predict(message, logprior, loglikelihood)))\n",
    "    p = naive_bayes_predict(message, logprior, loglikelihood)\n",
    "#     print(f'{message} -> {p:.2f} ({p_category})')\n",
    "    print(f'{message} -> {p:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e2ef98",
   "metadata": {},
   "source": [
    "### Expected Output :\n",
    "get an offer -> 1.00 <br>\n",
    "get the latest movie review -> 1.00 <br>\n",
    "order iphone -> 1.00 <br>\n",
    "I am on a meeting -> 0.00 <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "216fa97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feel free to check the sentiment of your own message below\n",
    "my_message = 'Feel free to check the sentiment of your own message below'\n",
    "naive_bayes_predict(my_message, logprior, loglikelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a45e4f0",
   "metadata": {},
   "source": [
    "### Expected Output :\n",
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e6e4d1",
   "metadata": {},
   "source": [
    "## Theory Questions: (15 points)\n",
    "\n",
    "1. When performing Naive Bayes operation especially for text classification, why is there a requirement for Laplace Smoothing or Additive Smoothing? Explain with considering an example of training and the test set and show how not having additive smoothing leads to undesirable outcomes. (10 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690ee011",
   "metadata": {},
   "source": [
    "##### Answer:\n",
    "##### Motivation for Laplace or Additive Smoothing: \n",
    "Consider the scenario where we are trying to classify some text where the test string contains certain words which are not present in the training dataset using which we calculated the likelihood of each word. \n",
    "\n",
    "In this case, the probability of the 'unknown' word in the test dataset would be zero and it will force the Overall probability which determines the classification to Zero (0). This is undesirable in the spam model since it will force the text to be classified as spam everytime there's an 'unknown' word in the training dataset.\n",
    "\n",
    "We can show how it affects the model with the below example: \n",
    "\n",
    "Step 1: Modify the train_naive_bayes() to not perform smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50dbd666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(freqs, train_x, train_y):\n",
    "    '''\n",
    "    Input:\n",
    "        freqs: dictionary from (word, label) to how often the word appears\n",
    "        train_x: a list of messages\n",
    "        train_y: a list of labels correponding to the messages (0,1)\n",
    "    Output:\n",
    "        logprior: the log prior. (equation 3 above)\n",
    "        loglikelihood: the log likelihood of you Naive bayes equation. (equation 6 above)\n",
    "    '''\n",
    "    loglikelihood = {}\n",
    "    logprior = 0\n",
    "\n",
    "\n",
    "    # calculate V, the number of unique words in the vocabulary\n",
    "    vocab = set([key[0] for key in freqs])\n",
    "    V = len(vocab)\n",
    "\n",
    "    # calculate num_pos and num_neg - the total number of positive and negative words for all documents\n",
    "    num_pos = num_neg = 0\n",
    "    for pair in freqs.keys():\n",
    "        # if the label is positive (greater than zero)\n",
    "        if pair[1]==1:\n",
    "            # Increment the number of positive words by the count for this (word, label) pair\n",
    "            num_pos+=freqs[pair]\n",
    "        # else, the label is negative\n",
    "        else:\n",
    "            # increment the number of negative words by the count for this (word,label) pair\n",
    "            num_neg +=freqs[pair]\n",
    "\n",
    "    # Calculate num_doc, the number of documents\n",
    "    num_doc = len(train_x)\n",
    "\n",
    "    # Calculate D_pos, the number of positive documents \n",
    "    pos_num_docs = train_y.sum()\n",
    "\n",
    "    # Calculate D_neg, the number of negative documents \n",
    "    neg_num_docs = num_doc-pos_num_docs\n",
    "\n",
    "    # Calculate logprior\n",
    "    logprior = np.log(pos_num_docs)-np.log(neg_num_docs)\n",
    "\n",
    "    # For each word in the vocabulary...\n",
    "    for word in vocab:\n",
    "        # get the positive and negative frequency of the word\n",
    "        freq_pos=freq_neg=0\n",
    "        if ((word,1) in freqs.keys()) :\n",
    "            freq_pos = freqs[(word,1)]\n",
    "        if((word, 0) in freqs.keys()):\n",
    "            freq_neg = freqs[(word, 0)]\n",
    "\n",
    "        # calculate the probability that each word is positive, and negative\n",
    "        #With smoothing\n",
    "        p_w_pos = (freq_pos)/(num_pos + V) #Smoothing is not performed here! \n",
    "        p_w_neg = (freq_neg)/(num_neg + V) #Smoothing is not performed here! \n",
    "\n",
    "        # calculate the log likelihood of the word\n",
    "        loglikelihood[word] = np.log(p_w_pos) - np.log(p_w_neg)\n",
    "\n",
    "\n",
    "    return logprior, loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0084646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new train dataset\n",
    "X_train_new= pd.Series(['get an offer', 'get the latest movie review', 'order iphone', 'I am on a meeting'])\n",
    "y_train_new=pd.Series([0,1,0,1])\n",
    "freqs_new = message_counter({}, X_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18c0d4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'review': inf, 'meet': inf, 'iphon': -inf, 'get': -0.08004270767353638, 'movi': inf, 'latest': inf, 'order': -inf, 'offer': -inf}\n"
     ]
    }
   ],
   "source": [
    "#Create Logprior and loglikelihood using the new train dataset\n",
    "logprior_new, loglikelihood_new = train_naive_bayes(freqs_new, X_train_new, y_train_new)\n",
    "print(loglikelihood_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c836ea",
   "metadata": {},
   "source": [
    "As seen by the loglikelihood calculated above we can see for those words which had a label missing the Loglikelihood is \n",
    "###### -infinity or +infinity\n",
    "\n",
    "This clearly breaks our classification model and hence the need for smoothing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9cf255",
   "metadata": {},
   "source": [
    "2. Why are logarithmic values computed for naive bayes algorithm rather than only the probability values? (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c9cd0b",
   "metadata": {},
   "source": [
    "##### Answer:\n",
    "\n",
    "For a large enough string, the probability of individual words can get really small. And therefore, multiplying all these tiny probabilities to find the product will yield even a smaller numerical value that often results in underflow which means that for that given test sentence, the trained model will fail to predict it’s category/sentiment. In order to avoid this underflow error, we use logarithmic values for naive bayes algorithm. \n",
    "\n",
    "Using logarithmic values is a natural choice because log increases or decreases monotonically which means that it will not affect the order of probabilities. Smaller probabilities will still stay smaller after the log has been applied to them and vice versa. Therefore, without affecting the predictions of trained model, we can effectively avoid the common pitfall of underflow error using Logarithmic values. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
